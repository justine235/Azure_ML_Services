{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Pipeline 0 : lecture (data_ingestion)\r\n",
    "# Pipeline 2 : processing ======================> to modify\r\n",
    "# Pipeline 3 : model vs automl\r\n",
    "# Pipepine 4 : hyperparameters\r\n",
    "# Pipeline 5 : save best model + save pipeline\r\n",
    "\r\n",
    "\r\n",
    "# + integrate metrics\r\n",
    "# + integrate fairness \r\n",
    "# + integrate explainability\r\n",
    "# + schedule end to end pipeline \r\n",
    "# + controle inference (best model + drift detector)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "%%writefile conda_dependencies.yml\r\n",
    "\r\n",
    "dependencies:\r\n",
    "- python=3.6.2\r\n",
    "- pip:\r\n",
    "  - azureml-defaults\r\n",
    "  - keras\r\n",
    "  - tensorflow<=2.4.*\r\n",
    "  - numpy\r\n",
    "  - scikit-learn\r\n",
    "  - pandas\r\n",
    "  - matplotlib"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "source": [
    "from azureml.core import Dataset\r\n",
    "from azureml.pipeline.steps import PythonScriptStep\r\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\r\n",
    "from azureml.core import Workspace, Dataset\r\n",
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from azureml.core import Workspace,RunConfiguration\r\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from azureml.pipeline.steps import AutoMLStep\r\n",
    "from azureml.train.automl.utilities import get_primary_metrics\r\n",
    "from azureml.data.datapath import DataPath\r\n",
    "from azureml.core.datastore import Datastore\r\n",
    "from azureml.pipeline.core import InputPortBinding\r\n",
    "from azureml.core import Run\r\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\r\n",
    "from azureml.pipeline.core import PipelineParameter\r\n",
    "from azureml.core import Dataset\r\n",
    "from azureml.core import Environment\r\n",
    "\r\n",
    "subscription_id = '---------'\r\n",
    "resource_group = 'learning'\r\n",
    "workspace_name = 'training_MLservices'\r\n",
    "\r\n",
    "# Step 0 environnement\r\n",
    "\r\n",
    "myenv = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')\r\n",
    "\r\n",
    "train_src = ScriptRunConfig(source_directory=script_folder,\r\n",
    "                            script='model_script2.py',\r\n",
    "                            compute_target=compute_target,\r\n",
    "                            environment=myenv)\r\n",
    "# Step 0 data ingestion\r\n",
    "raw_ds = Dataset.get_by_name(ws, name='trainingdataset', version=1)\r\n",
    "data_store = ws.get_default_datastore()\r\n",
    "prepared_ds = OutputFileDatasetConfig(destination=(datastore, 'outputdataset/{run-id}')).register_on_complete(name='prepared_ds')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Step 1 data preparation\r\n",
    "step1 = PythonScriptStep(name = 'prepare data',\r\n",
    "                         source_directory = 'scripts',\r\n",
    "                         script_name = 'data_prep.py',\r\n",
    "                         compute_target = 'jcharley2',\r\n",
    "                         # Script arguments include PipelineData\r\n",
    "                         arguments = ['--raw-ds', raw_ds.as_named_input('raw_data'),\r\n",
    "                                      '--out_folder', prepared_ds])\r\n",
    "\r\n",
    "# Step 2 Run Random Forest model\r\n",
    "step2 = PythonScriptStep(name = 'train model',\r\n",
    "                         source_directory = 'scripts',\r\n",
    "                         script_name = 'model_script2.py',\r\n",
    "                         compute_target = 'jcharley2',\r\n",
    "                         # Pass as script argument\r\n",
    "                         #arguments=[prepped_data.as_input(name='prepped_data')])\r\n",
    "                        arguments=[prepared_ds.read_delimited_files().as_input(name='prepared_ds')],\r\n",
    "                        runconfig=train_src.run_config)\r\n",
    "\r\n",
    "# Step 2 bis (choice 2 or 2 bis) Run AutomML\r\n",
    "automl_settings = {\r\n",
    "    \"iteration_timeout_minutes\" : 10,\r\n",
    "    \"iterations\" : 4,\r\n",
    "    \"experiment_timeout_hours\" : 0.10,\r\n",
    "    \"primary_metric\" : 'Precision'\r\n",
    "}\r\n",
    "\r\n",
    "aml_run_config = RunConfiguration()\r\n",
    "automl_config = AutoMLConfig(task = 'classification',\r\n",
    "                             path = '.',\r\n",
    "                             debug_log = 'automated_ml_errors.log',\r\n",
    "                             compute_target = 'jcharley2',\r\n",
    "                             run_configuration = aml_run_config,\r\n",
    "                             featurization = 'auto',\r\n",
    "                             training_data = [train_step_input],\r\n",
    "                             label_column_name = 'EmployeeTargeted',\r\n",
    "                             **automl_settings)\r\n",
    "                             \r\n",
    "# add to the pipeline\r\n",
    "step2_bis = AutoMLStep(name='AutoML',\r\n",
    "     automl_config=automl_config,\r\n",
    "     passthru_automl_config=False,\r\n",
    "     #outputs=[metrics_data,model_data],\r\n",
    "     enable_default_model_output=False,\r\n",
    "     enable_default_metrics_output=False,\r\n",
    "     allow_reuse=True)\r\n",
    "\r\n",
    "\r\n",
    "                   \r\n",
    "pipeline = Pipeline(workspace=ws, steps=[step1,step2], description=\"test-pipeline_3\")\r\n",
    "#pipelinebis = Pipeline(workspace=ws, steps=[step1,step2_bis], description=\"test-pipeline_3bis\")\r\n",
    "pipeline.submit(\"test-pipeline\", regenerate_outputs=True)\r\n",
    "\r\n",
    "\r\n",
    "#published_pipeline1 = pipeline_run1.publish_pipeline(\r\n",
    "#     name=\"Published_Titanic_Pipeline_Notebook\",\r\n",
    "#     description=\"Titanic_Pipeline_Notebook Published Pipeline Description\",\r\n",
    "#     version=\"1.0\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Created step prepare data [45245d52][aa48e885-e5c6-4619-a766-9ebe9997a5e9], (This step will run and generate new outputs)\n",
      "Created step train model [6b3cdd91][3cc9f3ca-01f7-40b3-9562-f82fa5b2db4c], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 49560045-af84-4b18-983c-e412ec75001a\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/49560045-af84-4b18-983c-e412ec75001a?wsid=/subscriptions/a0f4cddc-a66a-4dcc-9df7-ccbd7f81bf7b/resourcegroups/learning/workspaces/training_MLservices&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Run(Experiment: test-pipeline,\n",
       "Id: 49560045-af84-4b18-983c-e412ec75001a,\n",
       "Type: azureml.PipelineRun,\n",
       "Status: Running)"
      ],
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>test-pipeline</td><td>49560045-af84-4b18-983c-e412ec75001a</td><td>azureml.PipelineRun</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/49560045-af84-4b18-983c-e412ec75001a?wsid=/subscriptions/a0f4cddc-a66a-4dcc-9df7-ccbd7f81bf7b/resourcegroups/learning/workspaces/training_MLservices&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ]
     },
     "metadata": {},
     "execution_count": 194
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f4d2fc3f9599656570a986cacd0f8fb633e1f5eb6c0d7edd902095b821fab887"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
