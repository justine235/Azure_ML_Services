{
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "# This is auto generated from
        "# !pip install \"azure-ml-component[notebooks]\" --extra-index-url https://azuremlsdktestpypi.azureedge.net/modulesdkpreview --upgrade\n",
        "# More detailed guide to set up your environment: https://github.com/Azure/DesignerPrivatePreviewFeatures/blob/master/azure-ml-components/samples/setup-environment.ipynb\n",
        "# ------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azureml.core import Workspace\n",
        "from azure.ml.component import Pipeline, Component, dsl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# configure aml workspace\n",
        "ws = Workspace.from_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get components\n",
        "azureml_decision_forest_regression_func, azureml_score_model_func, azureml_evaluate_model_func, azureml_train_model_func, azureml_normalize_data_func, azureml_clean_missing_data_func, azureml_split_data_func = Component.batch_load(ws, selectors=['azureml://Decision Forest Regression', 'azureml://Score Model', 'azureml://Evaluate Model', 'azureml://Train Model', 'azureml://Normalize Data', 'azureml://Clean Missing Data', 'azureml://Split Data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get dataset\n",
        "from azureml.core import Dataset\n",
        "training = Dataset.get_by_name(ws, name='training', version=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define pipeline\n",
        "@dsl.pipeline(name='Pipeline-Created-on-07-30-2021', description='Pipeline created on 20210730', default_compute_target='jcharley1', default_datastore='workspaceblobstore')\n",
        "def generated_pipeline():\n",
        "    azureml_clean_missing_data_0 = azureml_clean_missing_data_func(\n",
        "        dataset=training,\n",
        "        columns_to_be_cleaned='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"Access_Level\"]}]',\n",
        "        minimum_missing_value_ratio=0.0,\n",
        "        maximum_missing_value_ratio=1.0,\n",
        "        cleaning_mode='Replace with mean',\n",
        "        generate_missing_value_indicator_column=False,\n",
        "        cols_with_all_missing_values='Remove',\n",
        "        replacement_value='0')\n",
        "    azureml_clean_missing_data_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_clean_missing_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_normalize_data_0 = azureml_normalize_data_func(\n",
        "        dataset=azureml_clean_missing_data_0.outputs.cleaned_dataset,\n",
        "        transformation_method='ZScore',\n",
        "        use_0_for_constant_columns_when_checked=True,\n",
        "        columns_to_transform='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"peerUsageMetric6\"]}]')\n",
        "    azureml_normalize_data_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_normalize_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_split_data_0 = azureml_split_data_func(\n",
        "        dataset=azureml_normalize_data_0.outputs.transformed_dataset,\n",
        "        splitting_mode='Split Rows',\n",
        "        fraction_of_rows_in_the_first_output_dataset=0.7,\n",
        "        randomized_split=True,\n",
        "        random_seed=0,\n",
        "        stratified_split='True',\n",
        "        stratification_key_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"EmployeeTargeted\"]}]',\n",
        "        regular_expression='\\\"column name\" ^start',\n",
        "        relational_expression='\\\"column name\" > 3')\n",
        "    azureml_split_data_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_split_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_decision_forest_regression_0 = azureml_decision_forest_regression_func(\n",
        "        create_trainer_mode='SingleParameter',\n",
        "        number_of_decision_trees=8,\n",
        "        maximum_depth_of_the_decision_trees=32,\n",
        "        minimum_number_of_samples_per_leaf_node=1,\n",
        "        resampling_method='Bagging Resampling',\n",
        "        range_for_number_of_decision_trees='1; 8; 32',\n",
        "        range_for_the_maximum_depth_of_the_decision_trees='1; 16; 64',\n",
        "        range_for_the_minimum_number_of_samples_per_leaf_node='1; 4; 16')\n",
        "    azureml_decision_forest_regression_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_decision_forest_regression_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_train_model_0 = azureml_train_model_func(\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset1,\n",
        "        untrained_model=azureml_decision_forest_regression_0.outputs.untrained_model,\n",
        "        label_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"EmployeeTargeted\"]}]',\n",
        "        model_explanations=False)\n",
        "    azureml_train_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_train_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_score_model_0 = azureml_score_model_func(\n",
        "        trained_model=azureml_train_model_0.outputs.trained_model,\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset2,\n",
        "        append_score_columns_to_output=True)\n",
        "    azureml_score_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_score_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\n",
        "    \n",
        "    azureml_evaluate_model_0 = azureml_evaluate_model_func(\n",
        "        scored_dataset=azureml_score_model_0.outputs.scored_dataset)\n",
        "    azureml_evaluate_model_0.runsettings.resource_layout.configure(node_count=1)\n",
        "    azureml_evaluate_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a pipeline\n",
        "pipeline = generated_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# validate pipeline and visualize the graph\n",
        "pipeline.validate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# submit a pipeline run\n",
        "# pipeline.submit(experiment_name='sample-experiment-name').wait_for_completion()"
      ]
    }
  ]
}
