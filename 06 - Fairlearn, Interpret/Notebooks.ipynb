{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#!pip install azureml-contrib-fairness\r\n",
    "#!pip install fairlearn==0.4.6\r\n",
    "#!pip install raiwidgets\r\n",
    "#pip install azureml-dataprep[pandas]\r\n",
    "\r\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.core.compute_target import ComputeTargetException\r\n",
    "from azureml.core import Environment\r\n",
    "from azureml.core import *\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies\r\n",
    "from azureml.core.runconfig import RunConfiguration\r\n",
    "from azureml.core import Workspace, Dataset, Datastore\r\n",
    "import os, shutil\r\n",
    "from azureml.core import Dataset\r\n",
    "from azureml.pipeline.steps import PythonScriptStep\r\n",
    "from azureml.pipeline.core import Pipeline, PipelineData\r\n",
    "from azureml.core import Workspace, Dataset\r\n",
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from azureml.core import Workspace,RunConfiguration\r\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from azureml.pipeline.steps import AutoMLStep\r\n",
    "from azureml.train.automl.utilities import get_primary_metrics\r\n",
    "from azureml.data.datapath import DataPath\r\n",
    "from azureml.core.datastore import Datastore\r\n",
    "from azureml.pipeline.core import InputPortBinding\r\n",
    "from azureml.core import Run\r\n",
    "from azureml.data.dataset_consumption_config import DatasetConsumptionConfig\r\n",
    "from azureml.pipeline.core import PipelineParameter\r\n",
    "from azureml.core import Dataset\r\n",
    "from azureml.core import Environment\r\n",
    "from azureml.pipeline.core import PipelineData, TrainingOutput\r\n",
    "from azureml.pipeline.steps import HyperDriveStep, HyperDriveStepRun, PythonScriptStep\r\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\r\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\r\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\r\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\r\n",
    "from azureml.data import OutputFileDatasetConfig\r\n",
    "from azureml.core import Experiment, ScriptRunConfig, Environment\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies\r\n",
    "from azureml.train.hyperdrive import *\r\n",
    "from azureml.widgets import RunDetails\r\n",
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\r\n",
    "from azureml.core import Run\r\n",
    "from azureml.core import get_run\r\n",
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "%%writefile conda_dependencies.yml\r\n",
    "\r\n",
    "dependencies:\r\n",
    "- python=3.6.2\r\n",
    "- pip:\r\n",
    "  - azureml-defaults\r\n",
    "  - keras\r\n",
    "  - tensorflow<=2.4.*\r\n",
    "  - numpy\r\n",
    "  - scikit-learn\r\n",
    "  - pandas\r\n",
    "  - matplotlib"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "subscription_id = '---------'\r\n",
    "resource_group = '----'\r\n",
    "workspace_name = 'interpretml'\r\n",
    "\r\n",
    "# connection au WS\r\n",
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()\r\n",
    "ws.get_details()\r\n",
    "myenv = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')\r\n",
    "\r\n",
    "\r\n",
    "# Create a Python environment for the experiment\r\n",
    "sklearn_env = Environment(\"sklearn-env\")\r\n",
    "\r\n",
    "# Ensure the required packages are installed\r\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\r\n",
    "                                    pip_packages=['azureml-defaults'])\r\n",
    "sklearn_env.python.conda_dependencies = packages\r\n",
    "\r\n",
    "# Create a script config + target compute ressource\r\n",
    "script_config = ScriptRunConfig(source_directory=\"scripts\",\r\n",
    "                                script='training_script.py',\r\n",
    "                                compute_target = 'jcharley3',\r\n",
    "                                environment=myenv) \r\n",
    "\r\n",
    "# Submit the experiment\r\n",
    "experiment = Experiment(workspace=ws, name='interpret2')\r\n",
    "run = experiment.submit(config=script_config)\r\n",
    "run.wait_for_completion()\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'runId': 'interpret2_1629749618_ec800433',\n",
       " 'target': 'jcharley3',\n",
       " 'status': 'Finalizing',\n",
       " 'startTimeUtc': '2021-08-23T20:14:26.18289Z',\n",
       " 'error': {'error': {'code': 'UserError',\n",
       "   'message': 'User program failed with SyntaxError: invalid syntax (training_script.py, line 24)',\n",
       "   'messageParameters': {},\n",
       "   'detailsUri': 'https://aka.ms/azureml-run-troubleshooting',\n",
       "   'details': []},\n",
       "  'time': '0001-01-01T00:00:00.000Z'},\n",
       " 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n",
       "  'ContentSnapshotId': 'cf4d560c-d76a-464c-bd71-1c23f41f47ed',\n",
       "  'ProcessInfoFile': 'azureml-logs/process_info.json',\n",
       "  'ProcessStatusFile': 'azureml-logs/process_status.json',\n",
       "  'azureml.git.repository_uri': 'https://github.com/justine235/Azure_ML_Services.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/justine235/Azure_ML_Services.git',\n",
       "  'azureml.git.branch': 'master',\n",
       "  'mlflow.source.git.branch': 'master',\n",
       "  'azureml.git.commit': 'bcebd4dcb2c40d4e56ca7018c7c7a4ae1f532d0a',\n",
       "  'mlflow.source.git.commit': 'bcebd4dcb2c40d4e56ca7018c7c7a4ae1f532d0a',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'training_script.py',\n",
       "  'command': '',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': [],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'jcharley3',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'datacaches': [],\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': 2592000,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'identity': None,\n",
       "  'environment': {'name': 'sklearn-env',\n",
       "   'version': 'Autosave_2021-08-23T20:01:40Z_3fa771d9',\n",
       "   'python': {'interpreterPath': 'python',\n",
       "    'userManagedDependencies': False,\n",
       "    'condaDependencies': {'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'keras',\n",
       "        'tensorflow<=2.4.*',\n",
       "        'numpy',\n",
       "        'scikit-learn',\n",
       "        'pandas',\n",
       "        'matplotlib']}],\n",
       "     'name': 'azureml_2742194f8253d6a33b53b4907cf6d42b'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210714.v1',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': True},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': None},\n",
       "  'aiSuperComputer': {'instanceType': 'AISupercomputer.D2',\n",
       "   'imageVersion': 'pytorch-1.7.0',\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None,\n",
       "   'interactive': False,\n",
       "   'scalePolicy': None,\n",
       "   'virtualClusterArmId': None,\n",
       "   'tensorboardLogDirectory': None,\n",
       "   'sshPublicKey': None,\n",
       "   'enableAzmlInt': True,\n",
       "   'priority': 'Medium',\n",
       "   'slaTier': 'Standard',\n",
       "   'userAlias': None},\n",
       "  'kubernetesCompute': {'instanceType': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []},\n",
       "  'environmentVariables': {},\n",
       "  'applicationEndpoints': {},\n",
       "  'parameters': [],\n",
       "  'dataBricks': {'workers': 0,\n",
       "   'minimumWorkerCount': 0,\n",
       "   'maxMumWorkerCount': 0,\n",
       "   'sparkVersion': '4.0.x-scala2.11',\n",
       "   'nodeTypeId': 'Standard_D3_v2',\n",
       "   'sparkConf': {},\n",
       "   'sparkEnvVars': {},\n",
       "   'instancePoolId': None,\n",
       "   'timeoutSeconds': 0,\n",
       "   'jarLibraries': [],\n",
       "   'eggLibraries': [],\n",
       "   'whlLibraries': [],\n",
       "   'pypiLibraries': [],\n",
       "   'rCranLibraries': [],\n",
       "   'mavenLibraries': []}},\n",
       " 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/55_azureml-execution-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt?sv=2019-07-07&sr=b&sig=8Vw42zsCam4GnLuRb%2Bk9XjibuFZVeAd6NY9P%2F3mOSR0%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'azureml-logs/65_job_prep-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/65_job_prep-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt?sv=2019-07-07&sr=b&sig=GXqOzzsDc6WFgo1GywV4mF%2BpzQAk3orE89jRfUq2EW8%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/70_driver_log.txt?sv=2019-07-07&sr=b&sig=wM0JDXPDOVnqqAM%2BpVtmf2uqkkKmPYSL3hmPMDTUrXE%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'azureml-logs/75_job_post-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/75_job_post-tvmps_f4ade6756a7a889077e5d1fee887b2dafcd70cb30e15a9485c0c1a3ba88d9d24_d.txt?sv=2019-07-07&sr=b&sig=KNWOADTKLBOQVOKI%2F4KeApPhCta3oJWFwvdKnQV0hwA%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'azureml-logs/process_info.json': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/process_info.json?sv=2019-07-07&sr=b&sig=AyHuU8a922%2FFNNS5gyGOFIqDQRx1pVHbVYFErA49XlA%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'azureml-logs/process_status.json': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/azureml-logs/process_status.json?sv=2019-07-07&sr=b&sig=lxoLqLLI3IfYaV37%2BGmif39GQgEsxCmHH8SBTU2Cfrs%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'logs/azureml/104_azureml.log': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/logs/azureml/104_azureml.log?sv=2019-07-07&sr=b&sig=qSJfDcDbWvfYlD3hykckl3Ej61pNins3pUPlocdY3tY%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'logs/azureml/job_prep_azureml.log': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/logs/azureml/job_prep_azureml.log?sv=2019-07-07&sr=b&sig=GtYhQ7GjShwykEnMFzIHj8D7AkDNP5AIhXYq4M%2F40tk%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r',\n",
       "  'logs/azureml/job_release_azureml.log': 'https://trainingstoragef39925970.blob.core.windows.net/azureml/ExperimentRun/dcid.interpret2_1629749618_ec800433/logs/azureml/job_release_azureml.log?sv=2019-07-07&sr=b&sig=pSAT6W3RsLCjUrMsv8JPCpg5I34eRZ%2FXzt811t8G4X4%3D&st=2021-08-23T20%3A04%3A40Z&se=2021-08-24T04%3A14%3A40Z&sp=r'},\n",
       " 'submittedBy': 'justine charley'}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Récupération des fichiers de modèle\r\n",
    "# List the files generated by the experiment\r\n",
    "for file in run.get_file_names():\r\n",
    "    print(file)\r\n",
    "\r\n",
    "# Create a model folder in the current directory\r\n",
    "os.makedirs('./output', exist_ok=True)\r\n",
    "\r\n",
    "# Download the model from run history\r\n",
    "run.register_model(model_name='model_save1', model_path='./output',description=\"Finetuning Similarity model\")\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "TRACKING DES MODELES - LOCAL"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Model\r\n",
    "model = Model.register(workspace=ws,\r\n",
    "                       model_name='rf',\r\n",
    "                       model_path='output/model.pkl', # local path\r\n",
    "                       description='rf test1',\r\n",
    "                       tags={'data-format': 'CSV'},\r\n",
    "                       model_framework=Model.Framework.SCIKITLEARN,\r\n",
    "                       model_framework_version='0.20.3')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Afficher les modèles inscrits"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Model\r\n",
    "\r\n",
    "for model in Model.list(ws):\r\n",
    "    # Get model name and auto-generated version\r\n",
    "    print(model.name, 'version:', model.version)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ENREGISTREMENT D'UN JEU DE DONNEES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.core import Dataset\r\n",
    "\r\n",
    "blob_ds = ws.get_default_datastore()\r\n",
    "csv_paths = [(blob_ds, 'data/train_dataset.csv')]\r\n",
    "tab_ds = Dataset.Tabular.from_delimited_files(path=csv_paths)\r\n",
    "tab_ds = tab_ds.register(workspace=ws, name='csv_table')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "RUN UN MODELE ENREGISTRE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.register_model( model_name='classification_model',\r\n",
    "                    model_path='outputs/model.pkl', # run outputs path\r\n",
    "                    description='A classification model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SCRIPT DE SCORING / INFERENCE TEMPS REELS\r\n",
    "En règle générale, vous utilisez la fonction init pour charger le modèle à partir du registre de modèles et la fonction run pour générer des prédictions à partir des données d’entrée. L’exemple de script suivant illustre ce modèle :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import json\r\n",
    "import joblib\r\n",
    "import numpy as np\r\n",
    "from azureml.core.model import Model\r\n",
    "\r\n",
    "# Called when the service is loaded\r\n",
    "def init():\r\n",
    "    global model\r\n",
    "    # Get the path to the registered model file and load it\r\n",
    "    model_path = Model.get_model_path('classification_model')\r\n",
    "    model = joblib.load(model_path)\r\n",
    "\r\n",
    "# Called when a request is received\r\n",
    "def run(raw_data):\r\n",
    "    # Get the input data as a numpy array\r\n",
    "    data = np.array(json.loads(raw_data)['data'])\r\n",
    "    # Get a prediction from the model\r\n",
    "    predictions = model.predict(data)\r\n",
    "    # Return the predictions as any JSON serializable format\r\n",
    "    return predictions.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Créer l'environnement associé\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies\r\n",
    "\r\n",
    "# Add the dependencies for your model\r\n",
    "myenv = CondaDependencies()\r\n",
    "myenv.add_conda_package(\"scikit-learn\")\r\n",
    "\r\n",
    "# Save the environment config as a .yml file\r\n",
    "env_file = 'service_files/env.yml'\r\n",
    "with open(env_file,\"w\") as f:\r\n",
    "    f.write(myenv.serialize_to_string())\r\n",
    "print(\"Saved dependency info in\", env_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Une fois toute la configuration préparée, vous pouvez déployer le modèle\r\n",
    "from azureml.core.model import Model\r\n",
    "\r\n",
    "model = ws.models['classification_model']\r\n",
    "service = Model.deploy(workspace=ws,\r\n",
    "                       name = 'classifier-service',\r\n",
    "                       models = [model],\r\n",
    "                       inference_config = classifier_inference_config,\r\n",
    "                       deployment_config = classifier_deploy_config,\r\n",
    "                       deployment_target = production_cluster)\r\n",
    "service.wait_for_deployment(show_output = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "ESPACE DE RECHERCHE / HYPERPARAMETRE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%%writefile conda_dependencies.yml\r\n",
    "\r\n",
    "dependencies:\r\n",
    "- python=3.6.2\r\n",
    "- scikit-learn=0.24.1\r\n",
    "- pip:\r\n",
    "  - numpy==1.19.5\r\n",
    "  - pandas==0.25.3\r\n",
    "  - azureml-defaults\r\n",
    "\r\n",
    "from azureml.core import Environment\r\n",
    "sklearn_env = Environment.from_conda_specification(name = 'sklearn-env', file_path = './conda_dependencies.yml')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#-------------------------- ETAPE 1 : MODEL INIT\r\n",
    "\r\n",
    "# connection au WS\r\n",
    "from azureml.core import Workspace\r\n",
    "ws = Workspace.from_config()\r\n",
    "ws.get_details()\r\n",
    "\r\n",
    "# Execution du script en tant qu'experience\r\n",
    "from azureml.core import Experiment, ScriptRunConfig, Environment\r\n",
    "from azureml.core.conda_dependencies import CondaDependencies\r\n",
    "from azureml.train.hyperdrive import HyperDriveConfig, PrimaryMetricGoal,RandomParameterSampling\r\n",
    "\r\n",
    "# Create a Python environment for the experiment\r\n",
    "#sklearn_env = Environment(\"sklearn-env\")\r\n",
    "\r\n",
    "# Ensure the required packages are installed\r\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\r\n",
    "                                    pip_packages=['azureml-defaults'])\r\n",
    "sklearn_env.python.conda_dependencies = packages\r\n",
    "\r\n",
    "# Create a script config + target compute ressource\r\n",
    "script_config = ScriptRunConfig(source_directory=\".\",\r\n",
    "                                script='training_script_hyperparametres.py',\r\n",
    "                                compute_target = 'jcharley2',\r\n",
    "                                environment=sklearn_env) \r\n",
    "\r\n",
    "# Submit the experiment\r\n",
    "experiment = Experiment(workspace=ws, name='test_hyperparametres')\r\n",
    "run  = experiment.submit(config=script_config)\r\n",
    "\r\n",
    "from azureml.widgets import RunDetails\r\n",
    "RunDetails(run).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save \r\n",
    "from azureml.core import Model\r\n",
    "from azureml.core.resource_configuration import ResourceConfiguration\r\n",
    "\r\n",
    "model = run.register_model(model_name='modele3', \r\n",
    "                           model_path='outputs/model.pkl',\r\n",
    "                           model_framework=Model.Framework.SCIKITLEARN,\r\n",
    "                           model_framework_version='0.24.1',\r\n",
    "                           resource_configuration=ResourceConfiguration(cpu=1, memory_in_gb=0.5))\r\n",
    "\r\n",
    "# deploy\r\n",
    "hosting_model = Model.deploy(ws, \"modele3\", [model])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "run.wait_for_completion(show_output=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#-------------------------- ETAPE 2 : TUNNING PARAMETERS\r\n",
    "# Espace de recherche des hyperparamètres\r\n",
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\r\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\r\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\r\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice\r\n",
    "    \r\n",
    "\r\n",
    "param_sampling = RandomParameterSampling( {\r\n",
    "    \"--n_estimators\": choice(15, 50, 100, 200, 300),\r\n",
    "    \"--criterion\": choice(\"gini\", \"entropy\")\r\n",
    "    }\r\n",
    ")\r\n",
    "\r\n",
    "\r\n",
    "hyperdrive_config = HyperDriveConfig(run_config=script_config,\r\n",
    "                                     hyperparameter_sampling=param_sampling, \r\n",
    "                                     primary_metric_name='accuracy',\r\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\r\n",
    "                                     max_total_runs=8,\r\n",
    "                                     max_concurrent_runs=4)\r\n",
    "\r\n",
    "# start the HyperDrive run\r\n",
    "hyperdrive_run = experiment.submit(hyperdrive_config)\r\n",
    "RunDetails(hyperdrive_run).show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for child_run in run.get_children():\r\n",
    "    print(child_run.id, child_run.get_metrics())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#-------------------------- ETAPE 3 : ENREGISTREMENT\r\n",
    "\r\n",
    "#récuperer le plus performant\r\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\r\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#host / save the best one \r\n",
    "model = best_run.register_model(model_name='rf_tuning', model_path='outputs/model_rf.joblib')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "f4d2fc3f9599656570a986cacd0f8fb633e1f5eb6c0d7edd902095b821fab887"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}