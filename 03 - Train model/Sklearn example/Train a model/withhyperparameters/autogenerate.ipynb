{
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# ------------------------------------------------------------------------------\r\n",
        "# This is auto generated  \r\n",
        "# To run this code, please install SDK by this command:\r\n",
        "# !pip install \"azure-ml-component[notebooks]\" --extra-index-url https://azuremlsdktestpypi.azureedge.net/modulesdkpreview --upgrade\r\n",
        "# More detailed guide to set up your environment: https://github.com/Azure/DesignerPrivatePreviewFeatures/blob/master/azure-ml-components/samples/setup-environment.ipynb\r\n",
        "# ------------------------------------------------------------------------------"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azureml.core import Workspace\r\n",
        "from azure.ml.component import Pipeline, Component, dsl"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# configure aml workspace\r\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get components\r\n",
        "azureml_score_model_func, azureml_evaluate_model_func, azureml_normalize_data_func, azureml_split_data_func, azureml_clean_missing_data_func, azureml_decision_forest_regression_func, azureml_tune_model_hyperparameters_func = Component.batch_load(ws, selectors=['azureml://Score Model', 'azureml://Evaluate Model', 'azureml://Normalize Data', 'azureml://Split Data', 'azureml://Clean Missing Data', 'azureml://Decision Forest Regression', 'azureml://Tune Model Hyperparameters'])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# get dataset\r\n",
        "from azureml.core import Dataset\r\n",
        "training = Dataset.get_by_name(ws, name='training', version=1)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# define pipeline\r\n",
        "@dsl.pipeline(name='pipeline hyperparametres', description='Pipeline-Created-on-07-30-2021', default_compute_target='jcharley1', default_datastore='workspaceblobstore')\r\n",
        "def generated_pipeline():\r\n",
        "    azureml_clean_missing_data_0 = azureml_clean_missing_data_func(\r\n",
        "        dataset=training,\r\n",
        "        columns_to_be_cleaned='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"Access_Level\"]}]',\r\n",
        "        minimum_missing_value_ratio=0.0,\r\n",
        "        maximum_missing_value_ratio=1.0,\r\n",
        "        cleaning_mode='Replace with mean',\r\n",
        "        generate_missing_value_indicator_column=False,\r\n",
        "        cols_with_all_missing_values='Remove',\r\n",
        "        replacement_value='0')\r\n",
        "    azureml_clean_missing_data_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_clean_missing_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_normalize_data_0 = azureml_normalize_data_func(\r\n",
        "        dataset=azureml_clean_missing_data_0.outputs.cleaned_dataset,\r\n",
        "        transformation_method='ZScore',\r\n",
        "        use_0_for_constant_columns_when_checked=True,\r\n",
        "        columns_to_transform='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"peerUsageMetric6\"]}]')\r\n",
        "    azureml_normalize_data_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_normalize_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_split_data_0 = azureml_split_data_func(\r\n",
        "        dataset=azureml_normalize_data_0.outputs.transformed_dataset,\r\n",
        "        splitting_mode='Split Rows',\r\n",
        "        fraction_of_rows_in_the_first_output_dataset=0.7,\r\n",
        "        randomized_split=True,\r\n",
        "        random_seed=0,\r\n",
        "        stratified_split='True',\r\n",
        "        stratification_key_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"EmployeeTargeted\"]}]',\r\n",
        "        regular_expression='\\\"column name\" ^start',\r\n",
        "        relational_expression='\\\"column name\" > 3')\r\n",
        "    azureml_split_data_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_split_data_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_decision_forest_regression_0 = azureml_decision_forest_regression_func(\r\n",
        "        create_trainer_mode='SingleParameter',\r\n",
        "        number_of_decision_trees=8,\r\n",
        "        maximum_depth_of_the_decision_trees=32,\r\n",
        "        minimum_number_of_samples_per_leaf_node=1,\r\n",
        "        resampling_method='Bagging Resampling',\r\n",
        "        range_for_number_of_decision_trees='1; 8; 32',\r\n",
        "        range_for_the_maximum_depth_of_the_decision_trees='1; 16; 64',\r\n",
        "        range_for_the_minimum_number_of_samples_per_leaf_node='1; 4; 16')\r\n",
        "    azureml_decision_forest_regression_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_decision_forest_regression_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_tune_model_hyperparameters_0 = azureml_tune_model_hyperparameters_func(\r\n",
        "        untrained_model=azureml_decision_forest_regression_0.outputs.untrained_model,\r\n",
        "        training_dataset=azureml_split_data_0.outputs.results_dataset1,\r\n",
        "        specify_parameter_sweeping_mode='Entire grid',\r\n",
        "        name_or_numerical_index_of_the_label_column='[{\"KeepInputDataOrder\":true,\"ColumnNames\":[\"EmployeeTargeted\"]}]',\r\n",
        "        metric_for_measuring_performance_for_classification='Accuracy',\r\n",
        "        metric_for_measuring_performance_for_regression='Mean absolute error',\r\n",
        "        maximum_number_of_runs_on_random_sweep=5,\r\n",
        "        random_seed=0)\r\n",
        "    azureml_tune_model_hyperparameters_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_tune_model_hyperparameters_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_score_model_0 = azureml_score_model_func(\r\n",
        "        trained_model=azureml_tune_model_hyperparameters_0.outputs.trained_best_model,\r\n",
        "        dataset=azureml_split_data_0.outputs.results_dataset2,\r\n",
        "        append_score_columns_to_output=True)\r\n",
        "    azureml_score_model_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_score_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')\r\n",
        "    \r\n",
        "    azureml_evaluate_model_0 = azureml_evaluate_model_func(\r\n",
        "        scored_dataset=azureml_score_model_0.outputs.scored_dataset)\r\n",
        "    azureml_evaluate_model_0.runsettings.resource_layout.configure(node_count=1)\r\n",
        "    azureml_evaluate_model_0.runsettings.docker_configuration.configure(use_docker=True, shared_volumes=True, shm_size='2g', arguments='[]')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# create a pipeline\r\n",
        "pipeline = generated_pipeline()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# validate pipeline and visualize the graph\r\n",
        "pipeline.validate()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# submit a pipeline run\r\n",
        "# pipeline.submit(experiment_name='sample-experiment-name').wait_for_completion()"
      ],
      "outputs": [],
      "metadata": {}
    }
  ]
}